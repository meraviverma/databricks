{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d42fbfd6",
   "metadata": {},
   "source": [
    "The user-defined functions are considered deterministic by default. Due to optimization, duplicate invocations may be eliminated or the function may even be invoked more times than it is present in the query. If your function is not deterministic, call asNondeterministic on the user defined function. E.g.:\n",
    "\n",
    "### def udf(f=None, returnType=StringType()):\n",
    "\n",
    "#### Parameters\n",
    "    ----------\n",
    "    f : function\n",
    "        python function if used as a standalone function\n",
    "    returnType : :class:`pyspark.sql.types.DataType` or str\n",
    "        the return type of the user-defined function. The value can be either a\n",
    "        :class:`pyspark.sql.types.DataType` object or a DDL-formatted type string.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1719b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "447dfdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SparkSession from builder\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\") \\\n",
    "                    .appName('UDF Pyspark') \\\n",
    "                    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb9b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a118b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import  udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5141341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c88c189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_udf=udf(lambda: int(random.random()*100),IntegerType()).asNondeterministic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd477df",
   "metadata": {},
   "outputs": [],
   "source": [
    "slen=udf(lambda s:len(s),IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be2e3c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf\n",
    "def to_upper(s):\n",
    "    if s is not None:\n",
    "        return s.upper()\n",
    "    \n",
    "@udf(returnType=IntegerType())\n",
    "def add_one(x):\n",
    "    if x is not None:\n",
    "        return x+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f70575a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+------------+\n",
      "|slen(name)|to_upper(name)|add_one(age)|\n",
      "+----------+--------------+------------+\n",
      "|         8|      JOHN DOE|          22|\n",
      "+----------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame([(1,\"John Doe\",21,\"johndoe@gmail.com\")],(\"id\",\"name\",\"age\",\"email\"))\n",
    "df.select(slen(\"name\").alias(\"slen(name)\"),to_upper(\"name\"),add_one(\"age\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0324f49",
   "metadata": {},
   "source": [
    "#### Define a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34e8eb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def first_letter_function(email):\n",
    "    return email[0]\n",
    "\n",
    "first_letter_function(\"anurag@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6a03284",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_letter_udf=udf(first_letter_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08cd2a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+------------+----------------------------+\n",
      "|slen(name)|to_upper(name)|add_one(age)|first_letter_function(email)|\n",
      "+----------+--------------+------------+----------------------------+\n",
      "|         8|      JOHN DOE|          22|                           j|\n",
      "+----------+--------------+------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(slen(\"name\").alias(\"slen(name)\"),to_upper(\"name\"),add_one(\"age\"),first_letter_udf(\"email\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0e6822",
   "metadata": {},
   "source": [
    "#### Register UDF to use in SQL\n",
    "Register the UDF using spark.udf.register to also make it available for use in the SQL namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0a8cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"emp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67bfea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_letter_udfsql=spark.udf.register(\"sql_udf\",first_letter_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b7352ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|sql_udf(email)|\n",
      "+--------------+\n",
      "|             j|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select sql_udf(email) from emp\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee7d00",
   "metadata": {},
   "source": [
    "### Pandas/Vectorized UDFs\n",
    "Pandas UDFs are available in Python to improve the efficiency of UDFs. Pandas UDFs utilize Apache Arrow to speed up computation.\n",
    "\n",
    "The user-defined functions are executed using:\n",
    "\n",
    "Apache Arrow, an in-memory columnar data format that is used in Spark to efficiently transfer data between JVM and Python processes with near-zero (de)serialization cost\n",
    "Pandas inside the function, to work with Pandas instances and APIs\n",
    "\n",
    "Pandas UDFs built on top of Apache Arrow bring you the best of both worldsâ€”the ability to define low-overhead, high-performance UDFs entirely in Python.\n",
    "\n",
    "In Spark 2.3, there will be two types of Pandas UDFs: scalar and grouped map. Next, we illustrate their usage using four example programs: Plus One, Cumulative Probability, Subtract Mean, Ordinary Least Squares Linear Regression.\n",
    "\n",
    "Scalar Pandas UDFs\n",
    "Scalar Pandas UDFs are used for vectorizing scalar operations. To define a scalar Pandas UDF, simply use @pandas_udf to annotate a Python function that takes in pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b40425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "\n",
    "# We have a string input/output\n",
    "@pandas_udf(\"string\")\n",
    "def vectorized_udf(email: pd.Series) -> pd.Series:\n",
    "    return email.str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb03c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_udf(email: pd.Series) -> pd.Series:\n",
    "     return email.str[0]\n",
    "vectorized_udf = pandas_udf(vectorized_udf, \"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a64fe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+------------+---------------------+\n",
      "|slen(name)|to_upper(name)|add_one(age)|vectorized_udf(email)|\n",
      "+----------+--------------+------------+---------------------+\n",
      "|         8|      JOHN DOE|          22|                    j|\n",
      "+----------+--------------+------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(slen(\"name\").alias(\"slen(name)\"),to_upper(\"name\"),add_one(\"age\"),vectorized_udf(\"email\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b5b60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
