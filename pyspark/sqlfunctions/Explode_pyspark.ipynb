{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9aa2b2",
   "metadata": {},
   "source": [
    "# Explode\n",
    "Returns a new row for each element in the given array or map.\n",
    "    Uses the default column name `col` for elements in the array and\n",
    "    `key` and `value` for elements in the map unless specified otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05367ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e61380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#reload(sys)\n",
    "#sys.setdefaultencoding(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399f4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SparkSession from builder\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\") \\\n",
    "                    .appName('Explode Pyspark') \\\n",
    "                    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fcd3d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0758f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode,explode_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73e14eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eDF=spark.createDataFrame([Row(a=1,intlist=[1,2,3],mapfield={\"a\":\"b\"})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3d4ab10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+\n",
      "|  a|  intlist|mapfield|\n",
      "+---+---------+--------+\n",
      "|  1|[1, 2, 3]|{a -> b}|\n",
      "+---+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd4455c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(anInt=1), Row(anInt=2), Row(anInt=3)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eDF.select(explode(eDF.intlist).alias(\"anInt\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86dac8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|key|value|\n",
      "+---+-----+\n",
      "|  a|    b|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eDF.select(explode(eDF.mapfield).alias(\"key\",\"value\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5d5aa5",
   "metadata": {},
   "source": [
    "## Working of Explode in PySpark with Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b687fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1  = [(\"Jhon\",[[\"USA\",\"MX\",\"USW\",\"UK\"],[\"23\",\"34\",\"56\"]]),(\"Joe\",[[\"IND\",\"AF\",\"YR\",\"QW\"],[\"22\",\"35\",\"76\"]]),(\"Juhi\",[[\"USA\",\"MX\",\"USW\",\"UK\"],[\"13\",\"64\",\"59\"]]),(\"Jhony\",[[\"USSR\",\"MXR\",\"USA\",\"UK\"],[\"22\",\"44\",\"76\"]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca6b6093",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = spark.createDataFrame(data=data1, schema = ['name','subjectandID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8cd5cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- subjectandID: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff9d1d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------------+\n",
      "|name |subjectandID                        |\n",
      "+-----+------------------------------------+\n",
      "|Jhon |[[USA, MX, USW, UK], [23, 34, 56]]  |\n",
      "|Joe  |[[IND, AF, YR, QW], [22, 35, 76]]   |\n",
      "|Juhi |[[USA, MX, USW, UK], [13, 64, 59]]  |\n",
      "|Jhony|[[USSR, MXR, USA, UK], [22, 44, 76]]|\n",
      "+-----+------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48d65e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = data_frame.select(data_frame.name,explode(data_frame.subjectandID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ea5751e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- col: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04bcb8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "| name|                 col|\n",
      "+-----+--------------------+\n",
      "| Jhon|  [USA, MX, USW, UK]|\n",
      "| Jhon|        [23, 34, 56]|\n",
      "|  Joe|   [IND, AF, YR, QW]|\n",
      "|  Joe|        [22, 35, 76]|\n",
      "| Juhi|  [USA, MX, USW, UK]|\n",
      "| Juhi|        [13, 64, 59]|\n",
      "|Jhony|[USSR, MXR, USA, UK]|\n",
      "|Jhony|        [22, 44, 76]|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8bba89",
   "metadata": {},
   "source": [
    "## Working of Explode in PySpark with Example-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8064d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One more Example\n",
    "data1  = [(\"Jhon\",[\"USA\",\"MX\",\"USW\",\"UK\"],{'23':'USA','34':'IND','56':'RSA'}),(\"Joe\",[\"IND\",\"AF\",\"YR\",\"QW\"],{'23':'USA','34':'IND','56':'RSA'}),(\"Juhi\",[\"USA\",\"MX\",\"USW\",\"UK\"],{'23':'USA','34':'IND','56':'RSA'}),(\"Jhony\",[\"USSR\",\"MXR\",\"USA\",\"UK\"],{'23':'USA','34':'IND','56':'RSA'})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b4d56c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame2 = spark.createDataFrame(data=data1, schema = ['name','subjectandID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfdfb27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- subjectandID: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- _3: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caedadda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---------------------------------+\n",
      "|name |subjectandID        |_3                               |\n",
      "+-----+--------------------+---------------------------------+\n",
      "|Jhon |[USA, MX, USW, UK]  |{56 -> RSA, 34 -> IND, 23 -> USA}|\n",
      "|Joe  |[IND, AF, YR, QW]   |{56 -> RSA, 34 -> IND, 23 -> USA}|\n",
      "|Juhi |[USA, MX, USW, UK]  |{56 -> RSA, 34 -> IND, 23 -> USA}|\n",
      "|Jhony|[USSR, MXR, USA, UK]|{56 -> RSA, 34 -> IND, 23 -> USA}|\n",
      "+-----+--------------------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e17da98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- col: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = data_frame2.select(data_frame2.name,explode(data_frame2.subjectandID))\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd900919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| name| col|\n",
      "+-----+----+\n",
      "| Jhon| USA|\n",
      "| Jhon|  MX|\n",
      "| Jhon| USW|\n",
      "| Jhon|  UK|\n",
      "|  Joe| IND|\n",
      "|  Joe|  AF|\n",
      "|  Joe|  YR|\n",
      "|  Joe|  QW|\n",
      "| Juhi| USA|\n",
      "| Juhi|  MX|\n",
      "| Juhi| USW|\n",
      "| Juhi|  UK|\n",
      "|Jhony|USSR|\n",
      "|Jhony| MXR|\n",
      "|Jhony| USA|\n",
      "|Jhony|  UK|\n",
      "+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ef6bf9",
   "metadata": {},
   "source": [
    "## Working of Explode in PySpark with Example - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55806a81",
   "metadata": {},
   "source": [
    "### The following code snippet explode an array column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "740e4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kontext=[{\"values\":[1,2,3,4,5]},{\"values\":[6,7,8]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a9a02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kontext_df=spark.createDataFrame(data=data_kontext,schema=['value1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89468a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|         value1|\n",
      "+---------------+\n",
      "|[1, 2, 3, 4, 5]|\n",
      "|      [6, 7, 8]|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kontext_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc3bdebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "kontext_df2=kontext_df.select(kontext_df.value1,explode(kontext_df.value1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50262aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---+\n",
      "|         value1|col|\n",
      "+---------------+---+\n",
      "|[1, 2, 3, 4, 5]|  1|\n",
      "|[1, 2, 3, 4, 5]|  2|\n",
      "|[1, 2, 3, 4, 5]|  3|\n",
      "|[1, 2, 3, 4, 5]|  4|\n",
      "|[1, 2, 3, 4, 5]|  5|\n",
      "|      [6, 7, 8]|  6|\n",
      "|      [6, 7, 8]|  7|\n",
      "|      [6, 7, 8]|  8|\n",
      "+---------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kontext_df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0351df79",
   "metadata": {},
   "source": [
    "### The following code snippet explode an Map column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b9e1bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kontext2 = [{\"values\": {\"a\": \"100\", \"b\": \"200\"}},\n",
    "        {\"values\": {\"a\": \"1000\", \"b\": \"2000\"}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14ba4667",
   "metadata": {},
   "outputs": [],
   "source": [
    "kontext_df2=spark.createDataFrame(data=data_kontext2,schema=['value1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d89b2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|value1                |\n",
      "+----------------------+\n",
      "|{a -> 100, b -> 200}  |\n",
      "|{a -> 1000, b -> 2000}|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kontext_df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ecfeeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kontext_df3=kontext_df2.select(kontext_df2.value1,explode(kontext_df2.value1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9932a2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---+-----+\n",
      "|value1                |key|value|\n",
      "+----------------------+---+-----+\n",
      "|{a -> 100, b -> 200}  |a  |100  |\n",
      "|{a -> 100, b -> 200}  |b  |200  |\n",
      "|{a -> 1000, b -> 2000}|a  |1000 |\n",
      "|{a -> 1000, b -> 2000}|b  |2000 |\n",
      "+----------------------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kontext_df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f948dca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|key|value|\n",
      "+---+-----+\n",
      "|  a|  100|\n",
      "|  b|  200|\n",
      "|  a| 1000|\n",
      "|  b| 2000|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kontext_df2.select(explode(kontext_df2.value1).alias(\"key\",\"value\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce43115b",
   "metadata": {},
   "source": [
    "## Working of Explode in PySpark with Example - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac4e82e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array_data = [(1, ['A']), (2, ['B','L','B']), (3, ['K','A','K']),(4, ['K']),\n",
    " (3, ['B','P'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "561c1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType,FloatType,ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3500a480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "882e6b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"Student_category\", IntegerType()),StructField(\"Student_full_name\", ArrayType(StringType()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1363abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(my_array_data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b35162b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+\n",
      "|Student_category|Student_full_name|\n",
      "+----------------+-----------------+\n",
      "|               1|              [A]|\n",
      "|               2|        [B, L, B]|\n",
      "|               3|        [K, A, K]|\n",
      "|               4|              [K]|\n",
      "|               3|           [B, P]|\n",
      "+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "501a327d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---+\n",
      "|Student_full_name|col|\n",
      "+-----------------+---+\n",
      "|              [A]|  A|\n",
      "|        [B, L, B]|  B|\n",
      "|        [B, L, B]|  L|\n",
      "|        [B, L, B]|  B|\n",
      "|        [K, A, K]|  K|\n",
      "|        [K, A, K]|  A|\n",
      "|        [K, A, K]|  K|\n",
      "|              [K]|  K|\n",
      "|           [B, P]|  B|\n",
      "|           [B, P]|  P|\n",
      "+-----------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Student_full_name\",explode('Student_full_name')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a42e3",
   "metadata": {},
   "source": [
    "## Working of Explode in PySpark with Example - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c28fad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array_data = [(1, []), (2, []), (3, []),(4, []), (3, [])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c7b56c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"Student_category\", IntegerType()),StructField(\"Student_full_name\", ArrayType(StringType()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "134c8fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(my_array_data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b764627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---+\n",
      "|Student_full_name|col|\n",
      "+-----------------+---+\n",
      "+-----------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Student_full_name\",explode('Student_full_name')).show()\n",
    "#It returns nothing since all the values are missing in the array column â€“ Student_full_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a7165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explode_outer() will return each and every individual value from an array. If the array is empty or null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5d10d",
   "metadata": {},
   "source": [
    "## Working of Explode in PySpark with Example - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b50e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider an array with 5 elements\n",
    "my_array_data = [(1, ['A']), (2, ['B','L','B']), (3, ['K','A','K']),\n",
    " (4, ['K']), (3, ['B','P'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a82221d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the StructType and StructFields\n",
    "#for the above data\n",
    "schema = StructType([StructField(\"Student_category\", IntegerType()),StructField(\"Student_full_name\", ArrayType(StringType()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ee32503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+\n",
      "|Student_category|Student_full_name|\n",
      "+----------------+-----------------+\n",
      "|               1|              [A]|\n",
      "|               2|        [B, L, B]|\n",
      "|               3|        [K, A, K]|\n",
      "|               4|              [K]|\n",
      "|               3|           [B, P]|\n",
      "+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create the dataframe and add schema to the dataframe\n",
    "df = spark.createDataFrame(my_array_data, schema=schema)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "caec10bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---+\n",
      "|Student_full_name|col|\n",
      "+-----------------+---+\n",
      "|              [A]|  A|\n",
      "|        [B, L, B]|  B|\n",
      "|        [B, L, B]|  L|\n",
      "|        [B, L, B]|  B|\n",
      "|        [K, A, K]|  K|\n",
      "|        [K, A, K]|  A|\n",
      "|        [K, A, K]|  K|\n",
      "|              [K]|  K|\n",
      "|           [B, P]|  B|\n",
      "|           [B, P]|  P|\n",
      "+-----------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# apply explode_outer on the Student_full_name column\n",
    "df.select(\"Student_full_name\",explode_outer('Student_full_name')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f28b106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
